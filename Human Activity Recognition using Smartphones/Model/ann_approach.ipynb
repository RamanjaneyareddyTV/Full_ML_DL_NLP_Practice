{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Human Activity Recognition using Smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a continuation of the above project where we have already performed the comparative analysis of multiple classifier models like Logisti Regression, Linear SVC, etc.\n",
    "### Now we are going to use Artificial Neural Network(ANN) approach to train our model and perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\KIIT\\Documents\\LGM-Soc contributions\\Human Activity Recognition using Smartphones\\Dataset/cleaned_train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\KIIT\\Documents\\LGM-Soc contributions\\Human Activity Recognition using Smartphones\\Dataset/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7342</th>\n",
       "      <th>7343</th>\n",
       "      <th>7344</th>\n",
       "      <th>7345</th>\n",
       "      <th>7346</th>\n",
       "      <th>7347</th>\n",
       "      <th>7348</th>\n",
       "      <th>7349</th>\n",
       "      <th>7350</th>\n",
       "      <th>7351</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tBodyAccmeanX</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>0.278419</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>0.276629</td>\n",
       "      <td>0.277199</td>\n",
       "      <td>0.279454</td>\n",
       "      <td>0.277432</td>\n",
       "      <td>0.277293</td>\n",
       "      <td>0.280586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276137</td>\n",
       "      <td>0.29423</td>\n",
       "      <td>0.221206</td>\n",
       "      <td>0.207861</td>\n",
       "      <td>0.237966</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.273853</td>\n",
       "      <td>0.273387</td>\n",
       "      <td>0.289654</td>\n",
       "      <td>0.351503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tBodyAccmeanY</th>\n",
       "      <td>-0.0202942</td>\n",
       "      <td>-0.0164106</td>\n",
       "      <td>-0.0194672</td>\n",
       "      <td>-0.0262006</td>\n",
       "      <td>-0.0165697</td>\n",
       "      <td>-0.0100979</td>\n",
       "      <td>-0.0196408</td>\n",
       "      <td>-0.0304883</td>\n",
       "      <td>-0.0217507</td>\n",
       "      <td>-0.0099603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108046</td>\n",
       "      <td>-0.0399683</td>\n",
       "      <td>-0.0363901</td>\n",
       "      <td>0.0634229</td>\n",
       "      <td>-0.00108781</td>\n",
       "      <td>-0.0571934</td>\n",
       "      <td>-0.00774933</td>\n",
       "      <td>-0.0170106</td>\n",
       "      <td>-0.018843</td>\n",
       "      <td>-0.0124231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tBodyAccmeanZ</th>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.12352</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.105137</td>\n",
       "      <td>-0.110022</td>\n",
       "      <td>-0.12536</td>\n",
       "      <td>-0.120751</td>\n",
       "      <td>-0.106065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056677</td>\n",
       "      <td>-0.143397</td>\n",
       "      <td>-0.167651</td>\n",
       "      <td>-0.220567</td>\n",
       "      <td>-0.148326</td>\n",
       "      <td>-0.181233</td>\n",
       "      <td>-0.147468</td>\n",
       "      <td>-0.0450218</td>\n",
       "      <td>-0.158281</td>\n",
       "      <td>-0.203867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tBodyAccstdX</th>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.99538</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.997335</td>\n",
       "      <td>-0.996921</td>\n",
       "      <td>-0.996559</td>\n",
       "      <td>-0.997328</td>\n",
       "      <td>-0.994803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230796</td>\n",
       "      <td>-0.230396</td>\n",
       "      <td>-0.176954</td>\n",
       "      <td>-0.244758</td>\n",
       "      <td>-0.218949</td>\n",
       "      <td>-0.195387</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.218218</td>\n",
       "      <td>-0.219139</td>\n",
       "      <td>-0.26927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tBodyAccstdY</th>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.9753</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990487</td>\n",
       "      <td>-0.967186</td>\n",
       "      <td>-0.966728</td>\n",
       "      <td>-0.961245</td>\n",
       "      <td>-0.972758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140521</td>\n",
       "      <td>-0.133669</td>\n",
       "      <td>-0.0501467</td>\n",
       "      <td>-0.0321591</td>\n",
       "      <td>-0.0129267</td>\n",
       "      <td>0.0399048</td>\n",
       "      <td>0.00481628</td>\n",
       "      <td>-0.103822</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>-0.0872115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angleXgravityMean</th>\n",
       "      <td>-0.841247</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>-0.849632</td>\n",
       "      <td>-0.85215</td>\n",
       "      <td>-0.851017</td>\n",
       "      <td>-0.847971</td>\n",
       "      <td>-0.848294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.830575</td>\n",
       "      <td>-0.799426</td>\n",
       "      <td>-0.787935</td>\n",
       "      <td>-0.780362</td>\n",
       "      <td>-0.797272</td>\n",
       "      <td>-0.791883</td>\n",
       "      <td>-0.77184</td>\n",
       "      <td>-0.779133</td>\n",
       "      <td>-0.785181</td>\n",
       "      <td>-0.783267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angleYgravityMean</th>\n",
       "      <td>0.179941</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.184823</td>\n",
       "      <td>0.18217</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.19031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213174</td>\n",
       "      <td>0.23549</td>\n",
       "      <td>0.24449</td>\n",
       "      <td>0.249624</td>\n",
       "      <td>0.234996</td>\n",
       "      <td>0.238604</td>\n",
       "      <td>0.252676</td>\n",
       "      <td>0.249145</td>\n",
       "      <td>0.246432</td>\n",
       "      <td>0.246809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angleZgravityMean</th>\n",
       "      <td>-0.0586269</td>\n",
       "      <td>-0.0543167</td>\n",
       "      <td>-0.0491178</td>\n",
       "      <td>-0.0476632</td>\n",
       "      <td>-0.0438923</td>\n",
       "      <td>-0.0421264</td>\n",
       "      <td>-0.04301</td>\n",
       "      <td>-0.0419758</td>\n",
       "      <td>-0.0373639</td>\n",
       "      <td>-0.0344173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00510524</td>\n",
       "      <td>-0.00164732</td>\n",
       "      <td>0.00953791</td>\n",
       "      <td>0.0278779</td>\n",
       "      <td>0.048907</td>\n",
       "      <td>0.0498191</td>\n",
       "      <td>0.0500526</td>\n",
       "      <td>0.0408112</td>\n",
       "      <td>0.0253395</td>\n",
       "      <td>0.0366948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activity</th>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>...</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows × 7352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0          1          2          3          4     \\\n",
       "tBodyAccmeanX       0.288585   0.278419   0.279653   0.279174   0.276629   \n",
       "tBodyAccmeanY     -0.0202942 -0.0164106 -0.0194672 -0.0262006 -0.0165697   \n",
       "tBodyAccmeanZ      -0.132905   -0.12352  -0.113462  -0.123283  -0.115362   \n",
       "tBodyAccstdX       -0.995279  -0.998245   -0.99538  -0.996091  -0.998139   \n",
       "tBodyAccstdY       -0.983111    -0.9753  -0.967187  -0.983403  -0.980817   \n",
       "...                      ...        ...        ...        ...        ...   \n",
       "angleXgravityMean  -0.841247  -0.844788  -0.848933  -0.848649  -0.847865   \n",
       "angleYgravityMean   0.179941   0.180289   0.180637   0.181935   0.185151   \n",
       "angleZgravityMean -0.0586269 -0.0543167 -0.0491178 -0.0476632 -0.0438923   \n",
       "subject                    1          1          1          1          1   \n",
       "Activity            STANDING   STANDING   STANDING   STANDING   STANDING   \n",
       "\n",
       "                        5          6          7          8          9     ...  \\\n",
       "tBodyAccmeanX       0.277199   0.279454   0.277432   0.277293   0.280586  ...   \n",
       "tBodyAccmeanY     -0.0100979 -0.0196408 -0.0304883 -0.0217507 -0.0099603  ...   \n",
       "tBodyAccmeanZ      -0.105137  -0.110022   -0.12536  -0.120751  -0.106065  ...   \n",
       "tBodyAccstdX       -0.997335  -0.996921  -0.996559  -0.997328  -0.994803  ...   \n",
       "tBodyAccstdY       -0.990487  -0.967186  -0.966728  -0.961245  -0.972758  ...   \n",
       "...                      ...        ...        ...        ...        ...  ...   \n",
       "angleXgravityMean  -0.849632   -0.85215  -0.851017  -0.847971  -0.848294  ...   \n",
       "angleYgravityMean   0.184823    0.18217   0.183779   0.188982    0.19031  ...   \n",
       "angleZgravityMean -0.0421264   -0.04301 -0.0419758 -0.0373639 -0.0344173  ...   \n",
       "subject                    1          1          1          1          1  ...   \n",
       "Activity            STANDING   STANDING   STANDING   STANDING   STANDING  ...   \n",
       "\n",
       "                               7342              7343              7344  \\\n",
       "tBodyAccmeanX              0.276137           0.29423          0.221206   \n",
       "tBodyAccmeanY             -0.108046        -0.0399683        -0.0363901   \n",
       "tBodyAccmeanZ             -0.056677         -0.143397         -0.167651   \n",
       "tBodyAccstdX              -0.230796         -0.230396         -0.176954   \n",
       "tBodyAccstdY              -0.140521         -0.133669        -0.0501467   \n",
       "...                             ...               ...               ...   \n",
       "angleXgravityMean         -0.830575         -0.799426         -0.787935   \n",
       "angleYgravityMean          0.213174           0.23549           0.24449   \n",
       "angleZgravityMean       -0.00510524       -0.00164732        0.00953791   \n",
       "subject                          30                30                30   \n",
       "Activity           WALKING_UPSTAIRS  WALKING_UPSTAIRS  WALKING_UPSTAIRS   \n",
       "\n",
       "                               7345              7346              7347  \\\n",
       "tBodyAccmeanX              0.207861          0.237966          0.299665   \n",
       "tBodyAccmeanY             0.0634229       -0.00108781        -0.0571934   \n",
       "tBodyAccmeanZ             -0.220567         -0.148326         -0.181233   \n",
       "tBodyAccstdX              -0.244758         -0.218949         -0.195387   \n",
       "tBodyAccstdY             -0.0321591        -0.0129267         0.0399048   \n",
       "...                             ...               ...               ...   \n",
       "angleXgravityMean         -0.780362         -0.797272         -0.791883   \n",
       "angleYgravityMean          0.249624          0.234996          0.238604   \n",
       "angleZgravityMean         0.0278779          0.048907         0.0498191   \n",
       "subject                          30                30                30   \n",
       "Activity           WALKING_UPSTAIRS  WALKING_UPSTAIRS  WALKING_UPSTAIRS   \n",
       "\n",
       "                               7348              7349              7350  \\\n",
       "tBodyAccmeanX              0.273853          0.273387          0.289654   \n",
       "tBodyAccmeanY           -0.00774933        -0.0170106         -0.018843   \n",
       "tBodyAccmeanZ             -0.147468        -0.0450218         -0.158281   \n",
       "tBodyAccstdX              -0.235309         -0.218218         -0.219139   \n",
       "tBodyAccstdY             0.00481628         -0.103822         -0.111412   \n",
       "...                             ...               ...               ...   \n",
       "angleXgravityMean          -0.77184         -0.779133         -0.785181   \n",
       "angleYgravityMean          0.252676          0.249145          0.246432   \n",
       "angleZgravityMean         0.0500526         0.0408112         0.0253395   \n",
       "subject                          30                30                30   \n",
       "Activity           WALKING_UPSTAIRS  WALKING_UPSTAIRS  WALKING_UPSTAIRS   \n",
       "\n",
       "                               7351  \n",
       "tBodyAccmeanX              0.351503  \n",
       "tBodyAccmeanY            -0.0124231  \n",
       "tBodyAccmeanZ             -0.203867  \n",
       "tBodyAccstdX               -0.26927  \n",
       "tBodyAccstdY             -0.0872115  \n",
       "...                             ...  \n",
       "angleXgravityMean         -0.783267  \n",
       "angleYgravityMean          0.246809  \n",
       "angleZgravityMean         0.0366948  \n",
       "subject                          30  \n",
       "Activity           WALKING_UPSTAIRS  \n",
       "\n",
       "[563 rows x 7352 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing and data preparation to feed data into Artificial Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64429225 0.48985291 0.43354743 ... 0.79825103 0.47068654 0.        ]\n",
      " [0.63920942 0.49179472 0.4382399  ... 0.79848665 0.47284164 0.        ]\n",
      " [0.63982653 0.49026642 0.44326915 ... 0.79872236 0.47544109 0.        ]\n",
      " ...\n",
      " [0.63669369 0.49149469 0.47748909 ... 0.84506893 0.52040559 1.        ]\n",
      " [0.64482708 0.49057848 0.42085971 ... 0.84323381 0.51266974 1.        ]\n",
      " [0.67575173 0.49378844 0.39806642 ... 0.84348837 0.51834742 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df.iloc[:,0:562])\n",
    "mat_train = scaler.transform(train_df.iloc[:,0:562])\n",
    "print(mat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6718788  0.55764282 0.52464834 ... 0.62209457 0.46362736 0.        ]\n",
      " [0.69470427 0.57426358 0.42707858 ... 0.62446791 0.45014396 0.        ]\n",
      " [0.68636345 0.55310221 0.42794829 ... 0.62380956 0.45251181 0.        ]\n",
      " ...\n",
      " [0.74529355 0.64526771 0.43015674 ... 0.62088108 0.58803909 1.        ]\n",
      " [0.65638384 0.62620241 0.44817885 ... 0.61581385 0.59135763 1.        ]\n",
      " [0.58994885 0.56560474 0.41032069 ... 0.61537208 0.59163879 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(test_df.iloc[:,0:562])\n",
    "mat_test = scaler.transform(test_df.iloc[:,0:562])\n",
    "print(mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in train_df.Activity:\n",
    "    if i == \"WALKING\": temp.append(0)\n",
    "    if i == \"WALKING_UPSTAIRS\": temp.append(1)\n",
    "    if i == \"WALKING_DOWNSTAIRS\": temp.append(2)\n",
    "    if i == \"SITTING\": temp.append(3)\n",
    "    if i == \"STANDING\": temp.append(4)\n",
    "    if i == \"LAYING\": temp.append(5)\n",
    "train_df[\"n_Activity\"] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in test_df.Activity:\n",
    "    if i == \"WALKING\": temp.append(0)\n",
    "    if i == \"WALKING_UPSTAIRS\": temp.append(1)\n",
    "    if i == \"WALKING_DOWNSTAIRS\": temp.append(2)\n",
    "    if i == \"SITTING\": temp.append(3)\n",
    "    if i == \"STANDING\": temp.append(4)\n",
    "    if i == \"LAYING\": temp.append(5)\n",
    "test_df[\"n_Activity\"] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop([\"Activity\"] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop([\"Activity\"] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(train_df.n_Activity , num_classes=6)\n",
    "y_test = to_categorical(test_df.n_Activity , num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mat_train \n",
    "X_test = mat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 562) (7352, 6)\n",
      "(2947, 562) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , y_train.shape)\n",
    "print(X_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Principle Component Analysis(PCA) approach for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=None)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "explained_variance=pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.15828106e-01, 5.06400451e-02, 4.26434706e-02, 1.86262004e-02,\n",
       "       1.66035347e-02, 1.24953315e-02, 1.16965425e-02, 1.08678969e-02,\n",
       "       9.83433293e-03, 8.50657174e-03, 8.37001183e-03, 7.05127957e-03,\n",
       "       6.70338404e-03, 5.99328732e-03, 5.41181394e-03, 4.88930458e-03,\n",
       "       4.73761525e-03, 4.55982869e-03, 4.23964053e-03, 4.11226497e-03,\n",
       "       4.09249242e-03, 3.86897287e-03, 3.70602160e-03, 3.53225460e-03,\n",
       "       3.41733672e-03, 3.24938911e-03, 3.10949303e-03, 3.04379473e-03,\n",
       "       2.98265122e-03, 2.88530149e-03, 2.80394457e-03, 2.70513498e-03,\n",
       "       2.62673924e-03, 2.56092694e-03, 2.38739329e-03, 2.37354154e-03,\n",
       "       2.25141457e-03, 2.17735852e-03, 2.08401681e-03, 2.06161176e-03,\n",
       "       2.03456493e-03, 1.96339691e-03, 1.91427414e-03, 1.81388346e-03,\n",
       "       1.77166464e-03, 1.70712611e-03, 1.67952873e-03, 1.61571929e-03,\n",
       "       1.58378870e-03, 1.55410378e-03, 1.50763285e-03, 1.44365153e-03,\n",
       "       1.40415069e-03, 1.36628463e-03, 1.32540485e-03, 1.27087175e-03,\n",
       "       1.22313443e-03, 1.19396945e-03, 1.15845173e-03, 1.12953011e-03,\n",
       "       1.10394772e-03, 1.08342091e-03, 1.06416138e-03, 1.04370643e-03,\n",
       "       1.01904647e-03, 1.00318899e-03, 9.60201676e-04, 9.53573748e-04,\n",
       "       9.33944190e-04, 8.90831704e-04, 8.65007560e-04, 8.49083411e-04,\n",
       "       8.39415876e-04, 8.17695830e-04, 8.01667795e-04, 7.84610426e-04,\n",
       "       7.77270715e-04, 7.68699706e-04, 7.59974704e-04, 7.32006710e-04,\n",
       "       7.23451736e-04, 7.09595536e-04, 6.88094238e-04, 6.70954720e-04,\n",
       "       6.67620103e-04, 6.57251737e-04, 6.49903563e-04, 6.30797432e-04,\n",
       "       6.28266549e-04, 6.13518569e-04, 6.09434231e-04, 5.96846016e-04,\n",
       "       5.86394342e-04, 5.75872805e-04, 5.52287704e-04, 5.50423009e-04,\n",
       "       5.44660889e-04, 5.28938545e-04, 5.24705156e-04, 5.14025519e-04,\n",
       "       5.09254818e-04, 5.02316952e-04, 4.86210351e-04, 4.79184242e-04,\n",
       "       4.70466306e-04, 4.68991209e-04, 4.62841025e-04, 4.53867482e-04,\n",
       "       4.47116573e-04, 4.33899748e-04, 4.24578366e-04, 4.22783321e-04,\n",
       "       4.18630179e-04, 3.89233673e-04, 3.84747878e-04, 3.75651195e-04,\n",
       "       3.72175571e-04, 3.66075157e-04, 3.58786731e-04, 3.51130840e-04,\n",
       "       3.42795325e-04, 3.33969065e-04, 3.31175254e-04, 3.23779475e-04,\n",
       "       3.15035658e-04, 3.13532813e-04, 3.08064594e-04, 3.00916878e-04,\n",
       "       2.92289942e-04, 2.87445693e-04, 2.78422174e-04, 2.74930448e-04,\n",
       "       2.68450803e-04, 2.63852235e-04, 2.55675292e-04, 2.50575145e-04,\n",
       "       2.48807155e-04, 2.40028375e-04, 2.39741956e-04, 2.37654246e-04,\n",
       "       2.36115677e-04, 2.29125380e-04, 2.22097705e-04, 2.16806489e-04,\n",
       "       2.15377330e-04, 2.10970982e-04, 2.08415201e-04, 2.05889670e-04,\n",
       "       2.01806331e-04, 1.99013154e-04, 1.96638940e-04, 1.85245665e-04,\n",
       "       1.80889608e-04, 1.77507243e-04, 1.75182926e-04, 1.70181742e-04,\n",
       "       1.62981989e-04, 1.60814838e-04, 1.59605828e-04, 1.57767597e-04,\n",
       "       1.53263339e-04, 1.51377426e-04, 1.48728767e-04, 1.45849106e-04,\n",
       "       1.45194901e-04, 1.42380107e-04, 1.39368279e-04, 1.33580458e-04,\n",
       "       1.31784789e-04, 1.30593271e-04, 1.27260768e-04, 1.26076075e-04,\n",
       "       1.24702067e-04, 1.22876181e-04, 1.19736756e-04, 1.16774870e-04,\n",
       "       1.15800907e-04, 1.14165107e-04, 1.12603706e-04, 1.11210632e-04,\n",
       "       1.10357822e-04, 1.07176602e-04, 1.06527628e-04, 1.04930104e-04,\n",
       "       1.02494894e-04, 1.01525972e-04, 9.89739619e-05, 9.77549465e-05,\n",
       "       9.43098320e-05, 9.36343655e-05, 9.32142043e-05, 8.96761929e-05,\n",
       "       8.93163367e-05, 8.81151776e-05, 8.71110581e-05, 8.56193269e-05,\n",
       "       8.33831319e-05, 8.08769486e-05, 7.97339736e-05, 7.93438082e-05,\n",
       "       7.87934173e-05, 7.65116153e-05, 7.52801564e-05, 7.49885511e-05,\n",
       "       7.46152207e-05, 7.33027120e-05, 7.25553183e-05, 7.17207086e-05,\n",
       "       6.99491117e-05, 6.84749475e-05, 6.73413402e-05, 6.70924682e-05,\n",
       "       6.46024486e-05, 6.43927161e-05, 6.43262236e-05, 6.24730214e-05,\n",
       "       6.17096622e-05, 6.01485603e-05, 5.86645826e-05, 5.84307794e-05,\n",
       "       5.62719123e-05, 5.57730709e-05, 5.50442832e-05, 5.37593391e-05,\n",
       "       5.34213319e-05, 5.27388840e-05, 5.19424641e-05, 5.07086297e-05,\n",
       "       5.03905767e-05, 4.92010727e-05, 4.89074781e-05, 4.84474467e-05,\n",
       "       4.73315592e-05, 4.67723795e-05, 4.62600788e-05, 4.52473220e-05,\n",
       "       4.47130927e-05, 4.40227217e-05, 4.34288613e-05, 4.27666046e-05,\n",
       "       4.21838622e-05, 4.15618387e-05, 4.13062441e-05, 4.07312363e-05,\n",
       "       3.98971794e-05, 3.85998888e-05, 3.81435384e-05, 3.77044406e-05,\n",
       "       3.64380828e-05, 3.62977522e-05, 3.55547803e-05, 3.45099925e-05,\n",
       "       3.40721924e-05, 3.33334729e-05, 3.31734090e-05, 3.30822829e-05,\n",
       "       3.23042119e-05, 3.20286696e-05, 3.13947318e-05, 3.11917603e-05,\n",
       "       3.11111876e-05, 2.99495898e-05, 2.95027360e-05, 2.92726527e-05,\n",
       "       2.86168000e-05, 2.78311589e-05, 2.76065808e-05, 2.70310319e-05,\n",
       "       2.67171816e-05, 2.65234117e-05, 2.60356380e-05, 2.56503196e-05,\n",
       "       2.48941262e-05, 2.45003152e-05, 2.39918439e-05, 2.35681415e-05,\n",
       "       2.33578445e-05, 2.30849165e-05, 2.28039704e-05, 2.26508981e-05,\n",
       "       2.16245830e-05, 2.14546398e-05, 2.08727329e-05, 2.07299982e-05,\n",
       "       2.03625548e-05, 2.00812609e-05, 1.97442989e-05, 1.95069159e-05,\n",
       "       1.89783770e-05, 1.86990148e-05, 1.82607697e-05, 1.81205751e-05,\n",
       "       1.78671096e-05, 1.75260451e-05, 1.72664315e-05, 1.70303385e-05,\n",
       "       1.67433543e-05, 1.66758051e-05, 1.65221690e-05, 1.62609823e-05,\n",
       "       1.61035709e-05, 1.57452661e-05, 1.55562151e-05, 1.54692568e-05,\n",
       "       1.50915046e-05, 1.48910960e-05, 1.48124323e-05, 1.45290846e-05,\n",
       "       1.44192686e-05, 1.42042636e-05, 1.38819299e-05, 1.36283812e-05,\n",
       "       1.33652275e-05, 1.32195554e-05, 1.30278704e-05, 1.28615029e-05,\n",
       "       1.25248365e-05, 1.23563309e-05, 1.20823508e-05, 1.16622389e-05,\n",
       "       1.14436667e-05, 1.09533103e-05, 1.06884404e-05, 1.04808143e-05,\n",
       "       1.03234864e-05, 1.01465070e-05, 9.87033355e-06, 9.82466276e-06,\n",
       "       9.70913670e-06, 9.66432833e-06, 9.35291738e-06, 9.17893162e-06,\n",
       "       8.98429452e-06, 8.87533007e-06, 8.72935298e-06, 8.50663279e-06,\n",
       "       8.38260073e-06, 8.25420457e-06, 8.04786393e-06, 7.53073825e-06,\n",
       "       7.27616182e-06, 7.09235104e-06, 7.02838697e-06, 6.93091675e-06,\n",
       "       6.89664663e-06, 6.77727899e-06, 6.27290629e-06, 6.13762174e-06,\n",
       "       5.91822225e-06, 5.85813140e-06, 5.74800545e-06, 5.60003635e-06,\n",
       "       5.22649084e-06, 5.17164237e-06, 4.90652911e-06, 4.85068769e-06,\n",
       "       4.73290170e-06, 4.44895873e-06, 4.32709897e-06, 4.29856292e-06,\n",
       "       4.17579805e-06, 3.95621260e-06, 3.94704777e-06, 3.88828433e-06,\n",
       "       3.65932939e-06, 3.63409436e-06, 3.44358336e-06, 3.38519537e-06,\n",
       "       3.22013387e-06, 3.11220990e-06, 3.06264371e-06, 3.03821731e-06,\n",
       "       2.92582678e-06, 2.89694953e-06, 2.80908875e-06, 2.72692904e-06,\n",
       "       2.67326260e-06, 2.63671150e-06, 2.61701230e-06, 2.55157303e-06,\n",
       "       2.48119315e-06, 2.42557605e-06, 2.35271464e-06, 2.28675367e-06,\n",
       "       2.19425924e-06, 2.11958294e-06, 2.05004358e-06, 1.97081070e-06,\n",
       "       1.90896214e-06, 1.82277973e-06, 1.71868555e-06, 1.67137949e-06,\n",
       "       1.60190940e-06, 1.56659552e-06, 1.54453772e-06, 1.49768953e-06,\n",
       "       1.43954449e-06, 1.43363865e-06, 1.39458439e-06, 1.35477225e-06,\n",
       "       1.28321846e-06, 1.23823810e-06, 1.21776626e-06, 1.17927421e-06,\n",
       "       1.16144861e-06, 1.10651306e-06, 1.08139450e-06, 1.05646156e-06,\n",
       "       1.01082853e-06, 9.80878991e-07, 9.59217879e-07, 9.31762414e-07,\n",
       "       8.97575472e-07, 8.56343449e-07, 8.31315316e-07, 8.05444855e-07,\n",
       "       7.80537144e-07, 7.50802719e-07, 7.23419750e-07, 7.02672223e-07,\n",
       "       6.61560330e-07, 6.43229877e-07, 6.20305005e-07, 6.08315544e-07,\n",
       "       5.85007527e-07, 5.57685879e-07, 5.41328839e-07, 5.17531934e-07,\n",
       "       4.80250905e-07, 4.61932858e-07, 4.51677380e-07, 4.19451197e-07,\n",
       "       3.69797951e-07, 3.53737607e-07, 3.35478451e-07, 2.78211071e-07,\n",
       "       2.09400588e-07, 2.08706058e-07, 1.79420173e-07, 1.57720928e-07,\n",
       "       1.10896930e-07, 1.08335932e-07, 8.68457911e-08, 8.18950913e-08,\n",
       "       7.28576822e-08, 6.10262487e-08, 5.11182124e-08, 3.54720822e-08,\n",
       "       3.30488943e-08, 3.09925190e-08, 2.75000568e-08, 2.14557022e-08,\n",
       "       1.93317877e-08, 1.72218019e-08, 1.54410456e-08, 1.41486412e-08,\n",
       "       1.22768248e-08, 9.97177771e-09, 9.84955991e-09, 9.10753367e-09,\n",
       "       8.66722662e-09, 7.15821825e-09, 6.88321444e-09, 6.81817170e-09,\n",
       "       3.10744182e-09, 1.22125114e-10, 9.32422654e-11, 1.89177262e-11,\n",
       "       3.71452153e-12, 9.39315796e-13, 1.16750729e-13, 1.90668882e-19,\n",
       "       1.82123096e-19, 1.71151492e-19, 1.66623563e-19, 1.65626634e-19,\n",
       "       1.63251849e-19, 1.60009839e-19, 1.59053073e-19, 1.56606049e-19,\n",
       "       1.55341519e-19, 1.54505524e-19, 1.52680841e-19, 1.52468823e-19,\n",
       "       1.50651856e-19, 1.50244004e-19, 1.49172359e-19, 1.48803195e-19,\n",
       "       1.48138654e-19, 1.47565541e-19, 1.46670119e-19, 1.45428576e-19,\n",
       "       1.44267911e-19, 1.43987277e-19, 1.42814096e-19, 1.42570319e-19,\n",
       "       1.41878896e-19, 1.40891610e-19, 1.40790251e-19, 1.40570314e-19,\n",
       "       1.39942869e-19, 1.39236572e-19, 1.38794421e-19, 1.38334925e-19,\n",
       "       1.37874354e-19, 1.36476242e-19, 1.35600481e-19, 1.35247344e-19,\n",
       "       1.33525953e-19, 1.33337971e-19, 1.32824426e-19, 1.31611555e-19,\n",
       "       1.31068568e-19, 1.30648158e-19, 1.29928023e-19, 1.29245690e-19,\n",
       "       1.28793616e-19, 1.28293335e-19, 1.27095477e-19, 1.26792878e-19,\n",
       "       1.26039944e-19, 1.25416658e-19, 1.24394135e-19, 1.23676812e-19,\n",
       "       1.23388960e-19, 1.23052569e-19, 1.22304120e-19, 1.21344768e-19,\n",
       "       1.20292125e-19, 1.19962794e-19, 1.19103143e-19, 1.18228491e-19,\n",
       "       1.17484262e-19, 1.16372731e-19, 1.16142317e-19, 1.14747939e-19,\n",
       "       1.14551520e-19, 1.14238138e-19, 1.13016956e-19, 1.11478654e-19,\n",
       "       1.09487582e-19, 3.35342172e-33, 3.35342172e-33, 3.35342172e-33,\n",
       "       3.35342172e-33, 3.35342172e-33, 3.35342172e-33, 3.35342172e-33,\n",
       "       3.35342172e-33, 3.35342172e-33, 3.35342172e-33, 3.35342172e-33,\n",
       "       3.35342172e-33, 3.35342172e-33, 3.35342172e-33, 3.35342172e-33,\n",
       "       3.35342172e-33, 3.16289550e-35, 2.02379051e-35, 9.86113518e-36,\n",
       "       5.19275817e-36, 5.85594901e-37])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout , BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                36032     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 196)               25284     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                6304      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 80,554\n",
      "Trainable params: 80,426\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=X_train.shape[1] , activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(196, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.0005),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                36032     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 196)               25284     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                6304      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 80,554\n",
      "Trainable params: 80,426\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "613/613 [==============================] - 4s 4ms/step - loss: 0.4755 - accuracy: 0.8251 - val_loss: 0.2572 - val_accuracy: 0.9019\n",
      "Epoch 2/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 0.3979 - val_accuracy: 0.8799\n",
      "Epoch 3/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0571 - accuracy: 0.9805 - val_loss: 0.5281 - val_accuracy: 0.8694\n",
      "Epoch 4/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.6340 - val_accuracy: 0.8456\n",
      "Epoch 5/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.3788 - val_accuracy: 0.8846\n",
      "Epoch 6/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.8076 - val_accuracy: 0.8191\n",
      "Epoch 7/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.6138 - val_accuracy: 0.8616\n",
      "Epoch 8/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.7430 - val_accuracy: 0.8612\n",
      "Epoch 9/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 1.1731 - val_accuracy: 0.8276\n",
      "Epoch 10/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.4255 - val_accuracy: 0.9091\n",
      "Epoch 11/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.4085 - val_accuracy: 0.9053\n",
      "Epoch 12/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0087 - accuracy: 0.9967 - val_loss: 0.5341 - val_accuracy: 0.9084\n",
      "Epoch 13/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.4609 - val_accuracy: 0.8890\n",
      "Epoch 14/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.3818 - val_accuracy: 0.9104\n",
      "Epoch 15/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.5206 - val_accuracy: 0.8965\n",
      "Epoch 16/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.5943 - val_accuracy: 0.9128\n",
      "Epoch 17/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.5529 - val_accuracy: 0.9121\n",
      "Epoch 18/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 1.0311 - val_accuracy: 0.8466\n",
      "Epoch 19/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.6797 - val_accuracy: 0.8527\n",
      "Epoch 20/50\n",
      "613/613 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.9335 - val_accuracy: 0.8636\n",
      "Epoch 21/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 1.0506 - val_accuracy: 0.8629\n",
      "Epoch 22/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.2047 - val_accuracy: 0.8670\n",
      "Epoch 23/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.8692 - val_accuracy: 0.8833\n",
      "Epoch 24/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.4560 - val_accuracy: 0.9260\n",
      "Epoch 25/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.6856 - val_accuracy: 0.8958\n",
      "Epoch 26/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 1.3423 - val_accuracy: 0.8497\n",
      "Epoch 27/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 1.3744 - val_accuracy: 0.8626\n",
      "Epoch 28/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 1.3738 - val_accuracy: 0.8398\n",
      "Epoch 29/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.6243 - val_accuracy: 0.8972\n",
      "Epoch 30/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.4039 - val_accuracy: 0.8958\n",
      "Epoch 31/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4561 - val_accuracy: 0.9199\n",
      "Epoch 32/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.5967 - val_accuracy: 0.8880\n",
      "Epoch 33/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.3023 - val_accuracy: 0.9389\n",
      "Epoch 34/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0162 - accuracy: 0.9984 - val_loss: 0.5653 - val_accuracy: 0.9023\n",
      "Epoch 35/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.4581 - val_accuracy: 0.9186\n",
      "Epoch 36/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.7673 - val_accuracy: 0.8860\n",
      "Epoch 37/50\n",
      "613/613 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.5677 - val_accuracy: 0.8904\n",
      "Epoch 38/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.7400 - val_accuracy: 0.8602\n",
      "Epoch 39/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.5781 - val_accuracy: 0.8985\n",
      "Epoch 40/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.7085 - val_accuracy: 0.8283\n",
      "Epoch 41/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.3976 - val_accuracy: 0.9036\n",
      "Epoch 42/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.7780 - val_accuracy: 0.8975\n",
      "Epoch 43/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7024 - val_accuracy: 0.9213\n",
      "Epoch 44/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.5758 - val_accuracy: 0.9220\n",
      "Epoch 45/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.9084 - val_accuracy: 0.8602\n",
      "Epoch 46/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.8381 - val_accuracy: 0.8456\n",
      "Epoch 47/50\n",
      "613/613 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.8516 - val_accuracy: 0.8578\n",
      "Epoch 48/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 9.4814e-04 - accuracy: 0.9998 - val_loss: 0.8377 - val_accuracy: 0.8687\n",
      "Epoch 49/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.5921 - val_accuracy: 0.8812\n",
      "Epoch 50/50\n",
      "613/613 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 1.2094 - val_accuracy: 0.8541\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=12,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CM = confusion_matrix(y_true, pred)\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(10, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90       496\n",
      "           1       0.96      0.65      0.78       471\n",
      "           2       0.68      1.00      0.81       420\n",
      "           3       0.69      0.96      0.80       491\n",
      "           4       0.96      0.69      0.80       532\n",
      "           5       1.00      0.97      0.98       537\n",
      "\n",
      "    accuracy                           0.85      2947\n",
      "   macro avg       0.88      0.85      0.85      2947\n",
      "weighted avg       0.89      0.85      0.85      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "print(classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\KIIT\\Documents\\LGM-Soc contributions\\Human Activity Recognition using Smartphones\\Model/activity_recognizer.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\KIIT\\Documents\\LGM-Soc contributions\\Human Activity Recognition using Smartphones\\Model/activity_recognizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { \"Index\":np.arange(2947) , \"Activity\":pred }\n",
    "final = pd.DataFrame(d)\n",
    "final.to_csv( 'ann_predictions.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
