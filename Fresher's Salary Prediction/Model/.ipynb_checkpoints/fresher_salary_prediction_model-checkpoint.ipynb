{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Data Visualization Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "## Machine Learning Libraries\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "## Regression Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "## Cross Val Score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['specialisation'] == 'Mkt&Fin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Info About Dataset,j\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Students which are not placed has salary 0.\n",
    "data['salary'] = data['salary'].replace(to_replace = np.nan, value= 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data):\n",
    "    data.drop_duplicates(keep='first',inplace=True)\n",
    "    return \"Checked Duplicates\"\n",
    "remove_duplicates(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_info_cate_data(dataset, categorical_col):\n",
    "    for index, col_name in enumerate(categorical_col):\n",
    "        print(categorical_col[index],'=', tuple(dataset[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_info_cate_data(data, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More Info About Categorical Data\n",
    "\n",
    "def more_info_cate_data(dataset, categorical_col):\n",
    "    for index, col_name in enumerate(categorical_col):\n",
    "        print('Total Number of Unique Variables in ',categorical_col[index],'columns is',dataset[col_name].nunique() ,'its Unique values are', dataset[col_name].unique())\n",
    "        print(dataset[col_name].value_counts())\n",
    "        print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_info_cate_data(data, categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in categorical_columns:\n",
    "    plt.figure() #this creates a new figure on which your plot will appear\n",
    "    sns.countplot(data[x],data=data);\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel('Salary')\n",
    "    plt.title(x)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropped unimportant columns\n",
    "\n",
    "data.drop(['sl_no'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships of Percentages with respect to Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = data.select_dtypes(exclude=['object']).columns.tolist()\n",
    "print(numerical_columns)\n",
    "for x in numerical_columns:\n",
    "    plt.figure()\n",
    "    sns.regplot(x=data[x], y=data['salary'], data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot of numerical data to check the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in numerical_columns:\n",
    "    plt.figure()\n",
    "    sns.boxplot(data[x]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Outliers From Salary Columns\n",
    "data = data[data['salary'] != 940000.0 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding Categorical Columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "data['gender'] = le_gender.fit_transform(data['gender'])\n",
    "print('gender',data['gender'].unique())\n",
    "\n",
    "le_ssc_b = LabelEncoder()\n",
    "data['ssc_b'] = le_ssc_b.fit_transform(data['ssc_b'])\n",
    "print('ssc_b',data['ssc_b'].unique())\n",
    "\n",
    "le_hsc_b = LabelEncoder()\n",
    "data['hsc_b'] = le_hsc_b.fit_transform(data['hsc_b'])\n",
    "print('hsc_b',data['hsc_b'].unique())\n",
    "\n",
    "le_hsc_s = LabelEncoder()\n",
    "data['hsc_s']  = le_hsc_s.fit_transform(data['hsc_s'])\n",
    "print('hsc_s',data['hsc_s'].unique())\n",
    "\n",
    "le_degree_t = LabelEncoder()\n",
    "data['degree_t']  = le_degree_t.fit_transform(data['degree_t'])\n",
    "print('degree_t',data['degree_t'].unique())\n",
    "\n",
    "le_workex = LabelEncoder()\n",
    "data['workex']  = le_workex.fit_transform(data['workex'])\n",
    "print('workex',data['workex'].unique())\n",
    "\n",
    "le_specialisation = LabelEncoder()\n",
    "data['specialisation']  = le_specialisation.fit_transform(data['specialisation'])\n",
    "print('specialisation',data['specialisation'].unique())\n",
    "\n",
    "le_status = LabelEncoder()\n",
    "data['status']  = le_status.fit_transform(data['status'])\n",
    "print('status',data['status'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into trianing and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('salary', axis = 1)\n",
    "y = data['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Importance \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_features = pd.Series(model.feature_importances_,index=X.columns)\n",
    "ranked_features.nlargest(13).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression_Model = LinearRegression()\n",
    "DecisionTreeRegression_Model = DecisionTreeRegressor()\n",
    "RandomForestRegression_Model = RandomForestRegressor()\n",
    "Xgboost_Model = xgb.XGBRegressor()\n",
    "Ridge_Model =  Ridge()\n",
    "Lasso_Model = Lasso()\n",
    "ElasticNet_Model = ElasticNet()\n",
    "\n",
    "ml_models = [LinearRegression_Model, DecisionTreeRegression_Model, RandomForestRegression_Model, Xgboost_Model, Ridge_Model, Lasso_Model, ElasticNet_Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracies = 0.0\n",
    "best_regressor = 0\n",
    "\n",
    "model_dict = {0:'LinearRegression', 1: 'DecisionTreeRegressor', 2: 'RandomForestRegressor', 3:'XgboostRegressor',4:'RidgeRegression',5:'LassoRegression',6:'ElsticNetRegression'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ml_models:\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, models in enumerate(ml_models):\n",
    "    y_pred = models.predict(X_test)\n",
    "    print( model_dict[i],models.score(X_test, y_test))\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax1 = sns.distplot(y_test, color='r', hist=False, label='Test Distribution')\n",
    "    ax2 = sns.distplot(y_pred, color='b', hist=False, label= 'Predicted Distribution')\n",
    "    plt.legend()\n",
    "    plt.title('Test vs Predicted Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, models in enumerate(ml_models):\n",
    "    print('Cross Validation Score of',model_dict[i],'is', (cross_val_score(models,X,y,cv=10)).mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, models in enumerate(ml_models):\n",
    "    y_pred = models.predict(X_test)\n",
    "    print( model_dict[i],np.sqrt(mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_test, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import median_absolute_error\n",
    "    \n",
    "    mean_error = mean_squared_error(y_test, y_pred)\n",
    "    root_mean_squared_error = np.sqrt(mean_error)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    absolute_error = mean_absolute_error(y_test, y_pred)\n",
    "    median_error = median_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print('Mean-Squared-Error:{}'.format(mean_error))\n",
    "    print('Root-Mean-Squared-Error:{}'.format(root_mean_squared_error))\n",
    "    print('Score:{}'.format(score))\n",
    "    print('Absolute Error:{}'.format(absolute_error))\n",
    "    print('Median-Absolute-Error:{}'.format(median_error))\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax1 = sns.distplot(y_test, color='r', hist=False, label='Test Distribution')\n",
    "    ax2 = sns.distplot(y_pred, color='b', hist=False, label= 'Predicted Distribution')\n",
    "    plt.legend()\n",
    "    plt.title('Test vs Predicted Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization of Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_regression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    regressor = LinearRegression()\n",
    "    \n",
    "    ## Parameters to tune\n",
    "    print('Parameters to be tune:{}'.format(LinearRegression().get_params().keys()))\n",
    "    \n",
    "    params = {\"copy_X\":[True, False],\n",
    "             \"fit_intercept\":[True, False],\n",
    "             \"normalize\":[True,False]}\n",
    "    grid = GridSearchCV(regressor, params, cv=5, scoring='r2',n_jobs=-1)\n",
    "    grid.fit(x_train, y_train)\n",
    "    y_pred = grid.predict(x_test)\n",
    "    \n",
    "    print('Best Hyperparameters Used:{}'.format(grid.best_params_))\n",
    "    \n",
    "    result = metric(y_test, y_pred)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization of Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    regressor = DecisionTreeRegressor()\n",
    "    \n",
    "    ## Parameters to be tune\n",
    "    print('Hyper-Parameters to be tune: {}'.format(DecisionTreeRegressor().get_params()))\n",
    "    \n",
    "    ## Setting and tuning the hyperparameters\n",
    "    \n",
    "    params = {\"criterion\":['mse','mae'],\n",
    "             \"min_samples_split\":[10,20,30,40],\n",
    "             \"max_depth\":[2,4,6,8],\n",
    "             \"min_samples_leaf\":[20, 40,60,100],\n",
    "             \"max_leaf_nodes\":[5,10,20,30]}\n",
    "    grid = GridSearchCV(regressor, params, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "    y_pred = grid.predict(x_test)\n",
    "    \n",
    "    ## Displaying the best hyperparameters used\n",
    "    print(\"Best Hyper-Parameters used : {}\".format(grid.best_params_))\n",
    "    \n",
    "    ## Setting the Metrics\n",
    "    result = metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization of Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "    \n",
    "    ## Parameters to be tune\n",
    "    print('Hyper-Parameters to be tune: {}'.format(RandomForestRegressor().get_params()))\n",
    "    \n",
    "    ## Setting and tuning the hyperparameters\n",
    "    \n",
    "    params = {\"n_estimators\":[10,20,30,40],\n",
    "             \"max_features\":['auto', 'log2', 'sqrt'],\n",
    "             \"bootstrap\":[True, False]}\n",
    "    grid = GridSearchCV(regressor, params, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "    y_pred = grid.predict(x_test)\n",
    "    \n",
    "    ## Displaying the best hyperparameters used\n",
    "    print(\"Best Hyper-Parameters used : {}\".format(grid.best_params_))\n",
    "    \n",
    "    ## Setting the Metrics\n",
    "    result = metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter of XGBoost Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost(x_train, x_test, y_train, y_test):\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    regressor = XGBRegressor()\n",
    "    \n",
    "    ## Parameters to be tune\n",
    "    print('Hyper-Parameters to be tune: {}'.format(XGBRegressor().get_params()))\n",
    "    \n",
    "    ## Setting and tuning the hyperparameters\n",
    "    \n",
    "    params = {\"nthread\":[3],\n",
    "             \"learning_rate\":[0.01, 0.03, 0.05, 0.06],\n",
    "             \"max_depth\":[4,5,6,8],\n",
    "             \"min_child_weight\":[4],\n",
    "             \"subsample\":[0.7],\n",
    "             \"colsample_bytree\":[0.7],\n",
    "             \"n_estimators\":[500]}\n",
    "    grid = GridSearchCV(regressor, params, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "    y_pred = grid.predict(x_test)\n",
    "    \n",
    "    ## Displaying the best hyperparameters used\n",
    "    print(\"Best Hyper-Parameters used : {}\".format(grid.best_params_))\n",
    "    \n",
    "    ## Setting the Metrics\n",
    "    result = metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =  xgb.XGBRegressor(colsample_bytree= 0.7, learning_rate = 0.01, max_depth= 4, min_child_weight= 4, n_estimators=500, nthread= 3, subsample= 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = X_test.values\n",
    "X_train_ = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_test_, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([['M',67.0,'Others',91.0,'Others','Commerce',58.0,'Sci&Tech','No',55.0,'Mkt&Fin',58.80,'Placed']])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0] = le_gender.transform(X[:,0])\n",
    "X[:,2] = le_ssc_b.transform(X[:,2])\n",
    "X[:,4] = le_hsc_b.transform(X[:,4])\n",
    "X[:,5] = le_hsc_s.transform(X[:,5])\n",
    "X[:,7] = le_degree_t.transform(X[:,7])\n",
    "X[:,8] = le_workex.transform(X[:,8])\n",
    "X[:,10] = le_specialisation.transform(X[:,10])\n",
    "X[:,12] = le_status.transform(X[:,12])\n",
    "\n",
    "X = X.astype(float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved the Model in Pickle Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"model\":model,\"le_gender\": le_gender, \"le_ssc_b\":le_ssc_b, \"le_hsc_b\":le_hsc_b, \"le_hsc_s\":le_hsc_s,\"le_degree_t\":le_degree_t,\"le_workex\":le_workex,\"le_specialisation\":le_specialisation,\"le_status\":le_status}\n",
    "with open('xgboost_model.pkl','wb') as file:\n",
    "    pickle.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgboost_model.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "regressor_loaded = data['model']\n",
    "le_gender = data['le_gender']\n",
    "le_ssc_b = data['le_ssc_b']\n",
    "le_hsc_b = data['le_hsc_b']\n",
    "le_hsc_s = data['le_hsc_s']\n",
    "le_degree_t = data['le_degree_t']\n",
    "le_workex = data['le_workex']\n",
    "le_specialisation = data['le_specialisation']\n",
    "le_status = data['le_status']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor_loaded.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit4c7b60b24e384a35a54eb90030c12cd8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
